{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f1bcc7b5",
      "metadata": {
        "id": "f1bcc7b5"
      },
      "source": [
        "# Install and Import Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2e02b5d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2e02b5d",
        "outputId": "06186043-2a0f-44de-cf48-284c0bf6c87c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 14862, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 14862 (delta 0), reused 1 (delta 0), pack-reused 14858\u001b[K\n",
            "Receiving objects: 100% (14862/14862), 13.92 MiB | 27.95 MiB/s, done.\n",
            "Resolving deltas: 100% (10231/10231), done.\n",
            "/content/yolov5\n",
            "\u001b[K     |████████████████████████████████| 182 kB 5.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 62 kB 427 kB/s \n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 45.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 42 kB 631 kB/s \n",
            "\u001b[K     |████████████████████████████████| 145 kB 8.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 178 kB 20.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 138 kB 68.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 67 kB 4.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 54 kB 1.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.3 MB/s \n",
            "\u001b[?25h  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Setup complete. Using torch 1.13.0+cu116 (CPU)\n"
          ]
        }
      ],
      "source": [
        "#clone YOLOv5 and \n",
        "!git clone https://github.com/ultralytics/yolov5  # clone repo\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt # install dependencies\n",
        "%pip install -q roboflow\n",
        "\n",
        "import torch\n",
        "import os\n",
        "from IPython.display import Image, clear_output  # to display images\n",
        "\n",
        "print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5eb071a2",
      "metadata": {
        "id": "5eb071a2"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f603bf2",
      "metadata": {
        "id": "8f603bf2"
      },
      "source": [
        "# Load Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36041399",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260,
          "referenced_widgets": [
            "72c31de2fcb247e5bf9362fe6f9621a4",
            "3f2e24910c90469a86cbd39b507b11ba",
            "f87048e62e3047d681cf7bbc5f9fab22",
            "d06e2f7335f14d038b48cad09755e215",
            "f380d5a3546a424f8616389a58aeae03",
            "f5f54322be2049f28a2f5352f2069ebd",
            "61fd4444b1e5493996729fe2728cdd0d",
            "055ececfcc2a428abed8e217f203713e",
            "5692fa79a51842c298f4e27fbbc84eda",
            "4d9e9b7a238449a5a8a82b5c2297099e",
            "59287c4afa5b4463bc4e84373cadb1ad"
          ]
        },
        "id": "36041399",
        "outputId": "bf24196d-c0e6-463d-c37d-2d6aad1cc9da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/hub.py:267: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n",
            "  warnings.warn(\n",
            "Downloading: \"https://github.com/ultralytics/yolov5/zipball/master\" to /root/.cache/torch/hub/master.zip\n",
            "YOLOv5 🚀 2022-12-24 Python-3.8.16 torch-1.13.0+cu116 CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '/usr/local/lib/python3.8/dist-packages/pyparsing-3.0.9.dist-info/METADATA'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt to yolov5s.pt...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/14.1M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "72c31de2fcb247e5bf9362fe6f9621a4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
            "Adding AutoShape... \n"
          ]
        }
      ],
      "source": [
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5s')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3da39708",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3da39708",
        "outputId": "46585cf2-38c7-4704-cbda-afb302e7b845"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AutoShape(\n",
              "  (model): DetectMultiBackend(\n",
              "    (model): DetectionModel(\n",
              "      (model): Sequential(\n",
              "        (0): Conv(\n",
              "          (conv): Conv2d(3, 32, kernel_size=(6, 6), stride=(2, 2), padding=(2, 2))\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (1): Conv(\n",
              "          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (2): C3(\n",
              "          (cv1): Conv(\n",
              "            (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (cv2): Conv(\n",
              "            (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (cv3): Conv(\n",
              "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (m): Sequential(\n",
              "            (0): Bottleneck(\n",
              "              (cv1): Conv(\n",
              "                (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "              (cv2): Conv(\n",
              "                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (3): Conv(\n",
              "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (4): C3(\n",
              "          (cv1): Conv(\n",
              "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (cv2): Conv(\n",
              "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (cv3): Conv(\n",
              "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (m): Sequential(\n",
              "            (0): Bottleneck(\n",
              "              (cv1): Conv(\n",
              "                (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "              (cv2): Conv(\n",
              "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "            )\n",
              "            (1): Bottleneck(\n",
              "              (cv1): Conv(\n",
              "                (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "              (cv2): Conv(\n",
              "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (5): Conv(\n",
              "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (6): C3(\n",
              "          (cv1): Conv(\n",
              "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (cv2): Conv(\n",
              "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (cv3): Conv(\n",
              "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (m): Sequential(\n",
              "            (0): Bottleneck(\n",
              "              (cv1): Conv(\n",
              "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "              (cv2): Conv(\n",
              "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "            )\n",
              "            (1): Bottleneck(\n",
              "              (cv1): Conv(\n",
              "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "              (cv2): Conv(\n",
              "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "            )\n",
              "            (2): Bottleneck(\n",
              "              (cv1): Conv(\n",
              "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "              (cv2): Conv(\n",
              "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (7): Conv(\n",
              "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (8): C3(\n",
              "          (cv1): Conv(\n",
              "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (cv2): Conv(\n",
              "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (cv3): Conv(\n",
              "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (m): Sequential(\n",
              "            (0): Bottleneck(\n",
              "              (cv1): Conv(\n",
              "                (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "              (cv2): Conv(\n",
              "                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (9): SPPF(\n",
              "          (cv1): Conv(\n",
              "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (cv2): Conv(\n",
              "            (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
              "        )\n",
              "        (10): Conv(\n",
              "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (11): Upsample(scale_factor=2.0, mode=nearest)\n",
              "        (12): Concat()\n",
              "        (13): C3(\n",
              "          (cv1): Conv(\n",
              "            (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (cv2): Conv(\n",
              "            (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (cv3): Conv(\n",
              "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (m): Sequential(\n",
              "            (0): Bottleneck(\n",
              "              (cv1): Conv(\n",
              "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "              (cv2): Conv(\n",
              "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (14): Conv(\n",
              "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (15): Upsample(scale_factor=2.0, mode=nearest)\n",
              "        (16): Concat()\n",
              "        (17): C3(\n",
              "          (cv1): Conv(\n",
              "            (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (cv2): Conv(\n",
              "            (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (cv3): Conv(\n",
              "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (m): Sequential(\n",
              "            (0): Bottleneck(\n",
              "              (cv1): Conv(\n",
              "                (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "              (cv2): Conv(\n",
              "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (18): Conv(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (19): Concat()\n",
              "        (20): C3(\n",
              "          (cv1): Conv(\n",
              "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (cv2): Conv(\n",
              "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (cv3): Conv(\n",
              "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (m): Sequential(\n",
              "            (0): Bottleneck(\n",
              "              (cv1): Conv(\n",
              "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "              (cv2): Conv(\n",
              "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (21): Conv(\n",
              "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (22): Concat()\n",
              "        (23): C3(\n",
              "          (cv1): Conv(\n",
              "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (cv2): Conv(\n",
              "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (cv3): Conv(\n",
              "            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (m): Sequential(\n",
              "            (0): Bottleneck(\n",
              "              (cv1): Conv(\n",
              "                (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "              (cv2): Conv(\n",
              "                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "                (act): SiLU(inplace=True)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (24): Detect(\n",
              "          (m): ModuleList(\n",
              "            (0): Conv2d(128, 255, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (1): Conv2d(256, 255, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (2): Conv2d(512, 255, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0f51762",
      "metadata": {
        "id": "f0f51762"
      },
      "source": [
        "#  Real Time Detections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e34f9994",
      "metadata": {
        "id": "e34f9994"
      },
      "outputs": [],
      "source": [
        "cap = cv2.VideoCapture(0)\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    \n",
        "    # Make detections \n",
        "    results = model(frame)\n",
        "    \n",
        "    cv2.imshow('YOLO', np.squeeze(results.render()))\n",
        "    \n",
        "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
        "        break\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c15e592",
      "metadata": {
        "id": "7c15e592"
      },
      "source": [
        "# Train from scratch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "try:\n",
        "  filename = take_photo()\n",
        "  print('Saved to {}'.format(filename))\n",
        "  \n",
        "  # Show the image which was just taken.\n",
        "  display(Image(filename))\n",
        "except Exception as err:\n",
        "  # Errors will be thrown if the user does not have a webcam or if they do not\n",
        "  # grant the page permission to access it.\n",
        "  print(str(err))"
      ],
      "metadata": {
        "id": "pb1PaLXBjlqr"
      },
      "id": "pb1PaLXBjlqr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4aaa351f",
      "metadata": {
        "id": "4aaa351f"
      },
      "outputs": [],
      "source": [
        "import uuid   # Unique identifier\n",
        "import os\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e9545a2",
      "metadata": {
        "id": "8e9545a2"
      },
      "outputs": [],
      "source": [
        "IMAGES_PATH = os.path.join('data', 'images') #/data/images\n",
        "labels = ['happy', 'sad']\n",
        "number_imgs = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52b49e7a",
      "metadata": {
        "id": "52b49e7a",
        "outputId": "250461c3-8719-48f3-b5a2-d5c4e098eb0f"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting images for happy\n",
            "Collecting images for happy, image number 0\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting images for happy, image number 1\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting images for happy, image number 2\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting images for happy, image number 3\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting images for happy, image number 4\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting images for happy, image number 5\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting images for happy, image number 6\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting images for happy, image number 7\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting images for happy, image number 8\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting images for happy, image number 9\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting images for happy, image number 10\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting images for happy, image number 11\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting images for happy, image number 12\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting images for happy, image number 13\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting images for happy, image number 14\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting images for happy, image number 15\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting images for happy, image number 16\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting images for happy, image number 17\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting images for happy, image number 18\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting images for happy, image number 19\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting images for sad\n",
            "Collecting images for sad, image number 0\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting images for sad, image number 1\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting images for sad, image number 2\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting images for sad, image number 3\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting images for sad, image number 4\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting images for sad, image number 5\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting images for sad, image number 6\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting images for sad, image number 7\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting images for sad, image number 8\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting images for sad, image number 9\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting images for sad, image number 10\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting images for sad, image number 11\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting images for sad, image number 12\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting images for sad, image number 13\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting images for sad, image number 14\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting images for sad, image number 15\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting images for sad, image number 16\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting images for sad, image number 17\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting images for sad, image number 18\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting images for sad, image number 19\n"
          ]
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import cv2\\nimport torch\\nimport numpy as np'); }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "cap = cv2.VideoCapture(0)\n",
        "# Loop through labels\n",
        "for label in labels:\n",
        "    print('Collecting images for {}'.format(label))\n",
        "    time.sleep(5)\n",
        "    \n",
        "    # Loop through image range\n",
        "    for img_num in range(number_imgs):\n",
        "        print('Collecting images for {}, image number {}'.format(label, img_num))\n",
        "        \n",
        "        # Webcam feed\n",
        "        ret, frame = cap.read()\n",
        "        \n",
        "        # Naming out image path\n",
        "        imgname = os.path.join(IMAGES_PATH, label+'.'+str(img_num)+'.jpg')\n",
        "        \n",
        "        # Writes out image to file \n",
        "        cv2.imwrite(imgname, frame)\n",
        "        \n",
        "        # Render to the screen\n",
        "        cv2.imshow('Image Collection', frame)\n",
        "        \n",
        "        # 2 second delay between captures\n",
        "        time.sleep(5)\n",
        "        \n",
        "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
        "            break\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0e21acc",
      "metadata": {
        "id": "a0e21acc",
        "outputId": "1b8a17a1-b325-42f8-eba8-b116124b64e6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'labelImg' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/tzutalin/labelImg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "497bbbf5",
      "metadata": {
        "id": "497bbbf5",
        "outputId": "d983cd2f-c432-4ea7-992c-7d0386213e70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: pyqt5 in c:\\users\\vishnu tripathi\\appdata\\roaming\\python\\python39\\site-packages (5.15.7)\n",
            "Requirement already satisfied: lxml in c:\\users\\vishnu tripathi\\appdata\\roaming\\python\\python39\\site-packages (4.9.2)\n",
            "Requirement already satisfied: PyQt5-sip<13,>=12.11 in c:\\users\\vishnu tripathi\\appdata\\roaming\\python\\python39\\site-packages (from pyqt5) (12.11.0)\n",
            "Requirement already satisfied: PyQt5-Qt5>=5.15.0 in c:\\users\\vishnu tripathi\\appdata\\roaming\\python\\python39\\site-packages (from pyqt5) (5.15.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyqt5 lxml --upgrade\n",
        "!cd labelImg && pyrcc5 -o libs/resources.py resources.qrc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d0231b4",
      "metadata": {
        "id": "4d0231b4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/test.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1pU_FLcaAen",
        "outputId": "d5a0b297-8e39-41c1-9d45-794448756ddd"
      },
      "id": "_1pU_FLcaAen",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/test.zip\n",
            "  inflating: test/I1_2009_12_14_drive_0082_000231.png  \n",
            "  inflating: test/I1_2009_12_14_drive_0082_000256.png  \n",
            "  inflating: test/I1_2009_12_14_drive_0082_000271.png  \n",
            "  inflating: test/I1_2009_12_14_drive_0082_000291.png  \n",
            "  inflating: test/I1_2009_12_14_drive_0082_000716.png  \n",
            "  inflating: test/I1_2009_12_14_drive_0083_000110.png  \n",
            "  inflating: test/I1_2009_12_14_drive_0086_000051.png  \n",
            "  inflating: test/I1_2009_12_14_drive_0086_000101.png  \n",
            "  inflating: test/I1_2009_12_14_drive_0086_000201.png  \n",
            "  inflating: test/I1_2009_12_14_drive_0088_000051.png  \n",
            "  inflating: test/I1_2009_12_14_drive_0088_000101.png  \n",
            "  inflating: test/I1_2009_12_14_drive_0089_000101.png  \n",
            "  inflating: test/I1_2009_12_14_drive_0090_000151.png  \n",
            "  inflating: test/I1_2009_12_14_drive_0092_000051.png  \n",
            "  inflating: test/I1_2009_12_14_drive_0093_000001.png  \n",
            "  inflating: test/I1_2009_12_14_drive_0095_000101.png  \n",
            "  inflating: test/I1_2009_12_14_drive_0098_000120.png  \n",
            "  inflating: test/I1_2009_12_14_drive_0101_000001.png  \n",
            "  inflating: test/I1_2009_12_14_drive_0101_000051.png  \n",
            "  inflating: test/I1_2009_12_14_drive_0101_000103.png  \n",
            "  inflating: test/I1_2009_12_14_drive_0102_000001.png  \n",
            "  inflating: test/I1_2009_12_14_drive_0102_000259.png  \n",
            "  inflating: test/I1_2009_12_14_drive_0103_000016.png  \n",
            "  inflating: test/I1_2010_03_04_drive_0002_000051.png  \n",
            "  inflating: test/I1_2010_03_04_drive_0002_000101.png  \n",
            "  inflating: test/I1_2010_03_04_drive_0003_000001.png  \n",
            "  inflating: test/I1_2010_03_04_drive_0003_000201.png  \n",
            "  inflating: test/I1_2010_03_04_drive_0004_000101.png  \n",
            "  inflating: test/I1_2010_03_04_drive_0004_000901.png  \n",
            "  inflating: test/I1_2010_03_04_drive_0004_001001.png  \n",
            "  inflating: test/I1_2010_03_04_drive_0004_001051.png  \n",
            "  inflating: test/I1_2010_03_04_drive_0006_000001.png  \n",
            "  inflating: test/I1_2010_03_04_drive_0007_000051.png  \n",
            "  inflating: test/I1_2010_03_04_drive_0008_000101.png  \n",
            "  inflating: test/I1_2010_03_04_drive_0008_000116.png  \n",
            "  inflating: test/I1_2010_03_04_drive_0008_000171.png  \n",
            "  inflating: test/I1_2010_03_04_drive_0008_000176.png  \n",
            "  inflating: test/I1_2010_03_04_drive_0009_000186.png  \n",
            "  inflating: test/I1_2010_03_04_drive_0009_000236.png  \n",
            "  inflating: test/I1_2010_03_04_drive_0010_000051.png  \n",
            "  inflating: test/I1_2010_03_04_drive_0010_000066.png  \n",
            "  inflating: test/I1_2010_03_04_drive_0010_000076.png  \n",
            "  inflating: test/I1_2010_03_04_drive_0010_000086.png  \n",
            "  inflating: test/I1_2010_03_04_drive_0011_000006.png  \n",
            "  inflating: test/I1_2010_03_04_drive_0012_000051.png  \n",
            "  inflating: test/I1_2010_03_04_drive_0013_000001.png  \n",
            "  inflating: test/I1_2010_03_04_drive_0013_000046.png  \n",
            "  inflating: test/I1_2010_03_04_drive_0013_000151.png  \n",
            "  inflating: test/I1_2010_03_04_drive_0013_000301.png  \n",
            "  inflating: test/I1_2010_03_04_drive_0013_000356.png  \n",
            "  inflating: test/I1_2010_03_04_drive_0013_000400.png  \n",
            "  inflating: test/I1_2010_03_04_drive_0014_000001.png  \n",
            "  inflating: test/I1_2010_03_04_drive_0014_000101.png  \n",
            "  inflating: test/I1_2010_03_04_drive_0014_000121.png  \n",
            "  inflating: test/I1_2010_03_04_drive_0014_000156.png  \n",
            "  inflating: test/I1_2010_03_04_drive_0014_000596.png  \n",
            "  inflating: test/I1_2010_03_04_drive_0015_000101.png  \n",
            "  inflating: test/I1_2010_03_04_drive_0017_000151.png  \n",
            "  inflating: test/I1_2010_03_04_drive_0017_000401.png  \n",
            "  inflating: test/I1_2010_03_04_drive_0018_000151.png  \n",
            "  inflating: test/I1_2010_03_04_drive_0019_000306.png  \n",
            "  inflating: test/I1_2010_03_04_drive_0020_000101.png  \n",
            "  inflating: test/I1_2010_03_04_drive_0021_000401.png  \n",
            "  inflating: test/I1_2010_03_04_drive_0021_000406.png  \n",
            "  inflating: test/I1_2010_03_04_drive_0023_000021.png  \n",
            "  inflating: test/I1_2010_03_04_drive_0023_000046.png  \n",
            "  inflating: test/I1_2010_03_04_drive_0024_000101.png  \n",
            "  inflating: test/I1_2010_03_04_drive_0027_000051.png  \n",
            "  inflating: test/I1_2010_03_04_drive_0027_000101.png  \n",
            "  inflating: test/I1_2010_03_04_drive_0027_000121.png  \n",
            "  inflating: test/I1_2010_03_04_drive_0028_000001.png  \n",
            "  inflating: test/I1_2010_03_04_drive_0028_000051.png  \n",
            "  inflating: test/I1_2010_03_04_drive_0029_000051.png  \n",
            "  inflating: test/I1_2010_03_04_drive_0031_000001.png  \n",
            "  inflating: test/I1_2010_03_04_drive_0031_000030.png  \n",
            "  inflating: test/I1_2010_03_04_drive_0032_000201.png  \n",
            "  inflating: test/I1_2010_03_04_drive_0033_000001.png  \n",
            "  inflating: test/I1_2010_03_04_drive_0033_000051.png  \n",
            "  inflating: test/I1_2010_03_04_drive_0033_000221.png  \n",
            "  inflating: test/I1_2010_03_04_drive_0034_000107.png  \n",
            "  inflating: test/I1_2010_03_04_drive_0035_000451.png  \n",
            "  inflating: test/I1_2010_03_04_drive_0035_000470.png  \n",
            "  inflating: test/I1_2010_03_04_drive_0038_000351.png  \n",
            "  inflating: test/I1_2010_03_04_drive_0038_000413.png  \n",
            "  inflating: test/I1_2010_03_04_drive_0039_000101.png  \n",
            "  inflating: test/I1_2010_03_04_drive_0039_000301.png  \n",
            "  inflating: test/I1_2010_03_04_drive_0039_000501.png  \n",
            "  inflating: test/I1_2010_03_04_drive_0040_000048.png  \n",
            "  inflating: test/I1_2010_03_04_drive_0041_000449.png  \n",
            "  inflating: test/I1_2010_03_04_drive_0042_000051.png  \n",
            "  inflating: test/I1_2010_03_04_drive_0043_000001.png  \n",
            "  inflating: test/I1_2010_03_05_drive_0006_000056.png  \n",
            "  inflating: test/I1_2010_03_05_drive_0006_000756.png  \n",
            "  inflating: test/I1_2010_03_05_drive_0006_000906.png  \n",
            "  inflating: test/I1_2010_03_05_drive_0007_000151.png  \n",
            "  inflating: test/I1_2010_03_05_drive_0009_000201.png  \n",
            "  inflating: test/I1_2010_03_05_drive_0009_000251.png  \n",
            "  inflating: test/I1_2010_03_05_drive_0012_000121.png  \n",
            "  inflating: test/I1_2010_03_05_drive_0012_000126.png  \n",
            "  inflating: test/I1_2010_03_05_drive_0012_000166.png  \n",
            "  inflating: test/I1_2010_03_05_drive_0012_000181.png  \n",
            "  inflating: test/I1_2010_03_05_drive_0013_000001.png  \n",
            "  inflating: test/I1_2010_03_05_drive_0013_000036.png  \n",
            "  inflating: test/I1_2010_03_05_drive_0014_000096.png  \n",
            "  inflating: test/I1_2010_03_05_drive_0014_000196.png  \n",
            "  inflating: test/I1_2010_03_05_drive_0014_000221.png  \n",
            "  inflating: test/I1_2010_03_05_drive_0014_000276.png  \n",
            "  inflating: test/I1_2010_03_05_drive_0015_000106.png  \n",
            "  inflating: test/I1_2010_03_05_drive_0015_000131.png  \n",
            "  inflating: test/I1_2010_03_05_drive_0015_000141.png  \n",
            "  inflating: test/I1_2010_03_05_drive_0015_000151.png  \n",
            "  inflating: test/I1_2010_03_05_drive_0015_000161.png  \n",
            "  inflating: test/I1_2010_03_05_drive_0015_000231.png  \n",
            "  inflating: test/I1_2010_03_05_drive_0015_000431.png  \n",
            "  inflating: test/I1_2010_03_05_drive_0016_000151.png  \n",
            "  inflating: test/I1_2010_03_05_drive_0016_000166.png  \n",
            "  inflating: test/I1_2010_03_05_drive_0016_000271.png  \n",
            "  inflating: test/I1_2010_03_05_drive_0016_000281.png  \n",
            "  inflating: test/I1_2010_03_05_drive_0016_000296.png  \n",
            "  inflating: test/I1_2010_03_05_drive_0017_000251.png  \n",
            "  inflating: test/I1_2010_03_05_drive_0017_000366.png  \n",
            "  inflating: test/I1_2010_03_05_drive_0017_000566.png  \n",
            "  inflating: test/I1_2010_03_05_drive_0017_000616.png  \n",
            "  inflating: test/I1_2010_03_05_drive_0017_000626.png  \n",
            "  inflating: test/I1_2010_03_05_drive_0017_000726.png  \n",
            "  inflating: test/I1_2010_03_05_drive_0017_000736.png  \n",
            "  inflating: test/I1_2010_03_05_drive_0017_000751.png  \n",
            "  inflating: test/I1_2010_03_05_drive_0017_000756.png  \n",
            "  inflating: test/I1_2010_03_05_drive_0018_000051.png  \n",
            "  inflating: test/I1_2010_03_05_drive_0018_000061.png  \n",
            "  inflating: test/I1_2010_03_05_drive_0018_000071.png  \n",
            "  inflating: test/I1_2010_03_05_drive_0018_000076.png  \n",
            "  inflating: test/I1_2010_03_05_drive_0018_000086.png  \n",
            "  inflating: test/I1_2010_03_05_drive_0018_000121.png  \n",
            "  inflating: test/I1_2010_03_05_drive_0018_000391.png  \n",
            "  inflating: test/I1_2010_03_05_drive_0018_000401.png  \n",
            "  inflating: test/I1_2010_03_05_drive_0018_000406.png  \n",
            "  inflating: test/I1_2010_03_05_drive_0018_000416.png  \n",
            "  inflating: test/I1_2010_03_05_drive_0018_000421.png  \n",
            "  inflating: test/I1_2010_03_05_drive_0018_000431.png  \n",
            "  inflating: test/I1_2010_03_05_drive_0018_000466.png  \n",
            "  inflating: test/I1_2010_03_05_drive_0018_000571.png  \n",
            "  inflating: test/I1_2010_03_05_drive_0018_000586.png  \n",
            "  inflating: test/I1_2010_03_05_drive_0018_000626.png  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/dataset.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwVnI1aD1oeo",
        "outputId": "5401ed83-af83-48ab-ff8f-c648668c3d5a"
      },
      "id": "CwVnI1aD1oeo",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/dataset.zip\n",
            "   creating: dataset/images/\n",
            "   creating: dataset/images/train/\n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0002_000051.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0002_000251.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0002_000401.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0002_000551.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0002_000701.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0002_001001.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0003_000301.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0003_000501.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0003_000801.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0003_000851.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0003_000901.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0003_000951.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0003_001001.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0003_001051.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0003_001101.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0003_001151.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0003_001201.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0003_001251.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0003_001401.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0003_001451.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0003_001501.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0003_001551.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0003_001601.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0003_001651.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0003_001701.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0003_001751.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0003_001801.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0003_001851.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0003_001901.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0003_001951.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0003_002001.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0003_002051.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0004_000001.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0004_000051.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0004_000101.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0004_000151.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0004_000201.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0004_000251.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0004_000351.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0004_000401.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0004_000501.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0004_000551.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0004_000601.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0004_000651.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0004_000701.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0004_000751.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0004_000951.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0004_001001.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0005_000051.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0005_000101.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0005_000351.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0005_000401.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0005_000551.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0005_000597.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0006_000001.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0006_000051.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0006_000151.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0006_000201.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0006_000351.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0007_000001.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0007_000201.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0007_000401.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0007_000451.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0007_000501.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0007_000551.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0007_000601.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0007_000901.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0007_001001.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0007_001051.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0007_001101.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0007_001151.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0007_001251.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0007_002251.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0007_002301.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0007_002351.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0007_002401.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0008_000051.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0008_000201.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0008_000251.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0008_000301.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0008_001001.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0008_001251.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0008_001301.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0008_001601.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0008_002001.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0008_002101.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0008_002401.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0008_002501.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0008_002601.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0008_002701.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0008_002751.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0008_002851.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0008_002882.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0009_000001.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0010_000001.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0010_000051.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0010_000101.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0010_000201.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0010_000301.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0010_000401.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0010_000501.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0010_000751.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0010_000851.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0010_000951.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0010_001001.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0010_001424.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0011_000051.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0011_000101.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0011_000251.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0011_000551.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0011_001301.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0011_001401.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0011_001451.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0011_001501.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0011_001801.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0012_000001.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0012_000051.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0012_000101.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0012_000151.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0012_000201.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0012_000301.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0012_000451.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0012_000601.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0012_000651.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0012_000901.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0012_001001.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0012_001051.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0012_001251.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0012_001351.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0012_001851.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0012_002001.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0012_002551.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0012_002579.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0013_000701.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0013_001251.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0014_000051.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0014_000101.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0014_000551.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0014_000651.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0015_000001.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0015_000101.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0015_000201.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0015_000316.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0015_000571.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0015_000721.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0015_000771.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0015_000821.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0015_001021.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0016_000151.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0016_000251.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0016_000296.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0016_000396.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0016_000446.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0016_000566.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0016_000766.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0016_000916.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0016_001066.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0017_000101.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0018_000001.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0018_000151.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0018_000851.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0018_000901.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0018_001451.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0019_000051.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0019_000251.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0019_000301.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0019_000796.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0020_000151.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0021_000476.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0023_000051.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0024_000101.png  \n",
            "  inflating: dataset/images/train/I1_2009_09_08_drive_0024_000301.png  \n",
            "  inflating: dataset/images/train/I1_2009_12_14_drive_0001_000001.png  \n",
            "  inflating: dataset/images/train/I1_2009_12_14_drive_0002_000186.png  \n",
            "  inflating: dataset/images/train/I1_2009_12_14_drive_0002_000206.png  \n",
            "  inflating: dataset/images/train/I1_2009_12_14_drive_0002_000306.png  \n",
            "  inflating: dataset/images/train/I1_2009_12_14_drive_0002_000326.png  \n",
            "  inflating: dataset/images/train/I1_2009_12_14_drive_0003_000301.png  \n",
            "  inflating: dataset/images/train/I1_2009_12_14_drive_0003_000431.png  \n",
            "  inflating: dataset/images/train/I1_2009_12_14_drive_0004_000101.png  \n",
            "  inflating: dataset/images/train/I1_2009_12_14_drive_0005_000101.png  \n",
            "  inflating: dataset/images/train/I1_2009_12_14_drive_0008_000101.png  \n",
            "  inflating: dataset/images/train/I1_2009_12_14_drive_0008_000301.png  \n",
            "  inflating: dataset/images/train/I1_2009_12_14_drive_0008_000601.png  \n",
            "  inflating: dataset/images/train/I1_2009_12_14_drive_0011_000151.png  \n",
            "  inflating: dataset/images/train/I1_2009_12_14_drive_0011_000309.png  \n",
            "  inflating: dataset/images/train/I1_2009_12_14_drive_0013_000201.png  \n",
            "  inflating: dataset/images/train/I1_2009_12_14_drive_0013_000251.png  \n",
            "  inflating: dataset/images/train/I1_2009_12_14_drive_0013_000301.png  \n",
            "  inflating: dataset/images/train/I1_2009_12_14_drive_0014_000351.png  \n",
            "  inflating: dataset/images/train/I1_2009_12_14_drive_0014_000411.png  \n",
            "  inflating: dataset/images/train/I1_2009_12_14_drive_0015_000051.png  \n",
            "  inflating: dataset/images/train/I1_2009_12_14_drive_0016_000111.png  \n",
            "  inflating: dataset/images/train/I1_2009_12_14_drive_0017_000001.png  \n",
            "  inflating: dataset/images/train/I1_2009_12_14_drive_0018_000201.png  \n",
            "  inflating: dataset/images/train/I1_2009_12_14_drive_0018_000251.png  \n",
            "  inflating: dataset/images/train/I1_2009_12_14_drive_0018_000299.png  \n",
            "  inflating: dataset/images/train/I1_2009_12_14_drive_0019_000101.png  \n",
            "  inflating: dataset/images/train/I1_2009_12_14_drive_0019_000106.png  \n",
            "  inflating: dataset/images/train/I1_2009_12_14_drive_0019_000111.png  \n",
            "   creating: dataset/images/val/\n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0019_000121.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0019_000131.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0019_000146.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0019_000166.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0019_000186.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0019_000231.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0020_000011.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0021_000101.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0021_000251.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0021_000401.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0021_000551.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0021_000701.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0021_000851.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0022_000128.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0023_000001.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0023_000551.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0023_000601.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0024_000101.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0024_000151.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0024_000201.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0025_000101.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0026_000001.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0026_000101.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0028_000151.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0029_000001.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0030_000100.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0031_000063.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0032_000001.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0033_000106.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0033_000111.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0033_000116.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0035_000051.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0037_000101.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0038_000001.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0038_000133.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0039_000201.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0040_000001.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0041_000151.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0042_000101.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0043_000066.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0045_000301.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0046_000001.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0046_000041.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0047_000051.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0048_000006.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0048_000161.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0049_000101.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0050_000109.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0055_000051.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0055_000151.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0056_000001.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0057_000051.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0058_000051.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0058_000151.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0058_000301.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0059_000051.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0060_000083.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0061_000074.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0062_000001.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0062_000051.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0062_000061.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0062_000076.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0062_000091.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0062_000106.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0063_000201.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0063_000256.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0064_000001.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0066_000001.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0068_000001.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0069_000251.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0070_000051.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0071_000051.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0072_000001.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0074_000001.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0077_000001.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0078_000251.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0079_000301.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0080_000051.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0081_000001.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0081_000151.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0082_000101.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0082_000146.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0082_000151.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0082_000161.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0082_000176.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0082_000191.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0082_000206.png  \n",
            "  inflating: dataset/images/val/I1_2009_12_14_drive_0082_000221.png  \n",
            "   creating: dataset/labels/\n",
            "  inflating: dataset/labels/classes.txt  \n",
            "  inflating: dataset/labels/train.cache  \n",
            "   creating: dataset/labels/train/\n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0002_000051.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0002_000251.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0002_000401.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0002_000551.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0002_000701.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0002_001001.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0003_000301.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0003_000501.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0003_000801.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0003_000851.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0003_000901.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0003_000951.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0003_001001.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0003_001051.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0003_001101.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0003_001151.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0003_001201.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0003_001251.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0003_001401.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0003_001451.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0003_001501.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0003_001551.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0003_001601.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0003_001651.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0003_001701.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0003_001751.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0003_001801.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0003_001851.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0003_001901.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0003_001951.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0003_002001.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0003_002051.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0004_000001.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0004_000051.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0004_000101.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0004_000151.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0004_000201.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0004_000251.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0004_000351.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0004_000401.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0004_000501.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0004_000551.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0004_000601.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0004_000651.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0004_000701.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0004_000751.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0004_000951.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0004_001001.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0005_000051.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0005_000101.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0005_000351.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0005_000401.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0005_000551.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0005_000597.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0006_000001.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0006_000051.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0006_000151.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0006_000201.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0006_000351.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0007_000001.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0007_000201.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0007_000401.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0007_000451.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0007_000501.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0007_000551.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0007_000601.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0007_000901.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0007_001001.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0007_001051.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0007_001101.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0007_001151.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0007_001251.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0007_002251.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0007_002301.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0007_002351.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0007_002401.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0008_000051.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0008_000201.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0008_000251.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0008_000301.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0008_001001.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0008_001251.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0008_001301.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0008_001601.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0008_002001.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0008_002101.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0008_002401.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0008_002501.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0008_002601.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0008_002701.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0008_002751.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0008_002851.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0008_002882.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0009_000001.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0010_000001.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0010_000051.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0010_000101.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0010_000201.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0010_000301.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0010_000401.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0010_000501.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0010_000751.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0010_000851.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0010_000951.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0010_001001.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0010_001424.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0011_000051.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0011_000101.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0011_000251.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0011_000551.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0011_001301.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0011_001401.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0011_001451.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0011_001501.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0011_001801.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0012_000001.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0012_000051.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0012_000101.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0012_000151.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0012_000201.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0012_000301.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0012_000451.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0012_000601.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0012_000651.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0012_000901.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0012_001001.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0012_001051.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0012_001251.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0012_001351.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0012_001851.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0012_002001.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0012_002551.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0012_002579.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0013_000701.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0013_001251.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0014_000051.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0014_000101.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0014_000551.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0014_000651.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0015_000001.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0015_000101.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0015_000201.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0015_000316.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0015_000571.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0015_000721.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0015_000771.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0015_000821.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0015_001021.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0016_000151.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0016_000251.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0016_000296.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0016_000396.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0016_000446.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0016_000566.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0016_000766.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0016_000916.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0016_001066.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0017_000101.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0018_000001.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0018_000151.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0018_000851.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0018_000901.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0018_001451.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0019_000051.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0019_000251.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0019_000301.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0019_000796.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0020_000151.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0021_000476.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0023_000051.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0024_000101.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_09_08_drive_0024_000301.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_12_14_drive_0001_000001.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_12_14_drive_0002_000186.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_12_14_drive_0002_000206.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_12_14_drive_0002_000306.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_12_14_drive_0002_000326.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_12_14_drive_0003_000301.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_12_14_drive_0003_000431.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_12_14_drive_0004_000101.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_12_14_drive_0005_000101.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_12_14_drive_0008_000101.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_12_14_drive_0008_000301.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_12_14_drive_0008_000601.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_12_14_drive_0011_000151.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_12_14_drive_0011_000309.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_12_14_drive_0013_000201.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_12_14_drive_0013_000251.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_12_14_drive_0013_000301.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_12_14_drive_0014_000351.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_12_14_drive_0014_000411.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_12_14_drive_0015_000051.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_12_14_drive_0016_000111.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_12_14_drive_0017_000001.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_12_14_drive_0018_000201.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_12_14_drive_0018_000251.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_12_14_drive_0018_000299.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_12_14_drive_0019_000101.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_12_14_drive_0019_000106.txt  \n",
            "  inflating: dataset/labels/train/I1_2009_12_14_drive_0019_000111.txt  \n",
            "  inflating: dataset/labels/val.cache  \n",
            "   creating: dataset/labels/val/\n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0019_000121.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0019_000131.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0019_000146.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0019_000166.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0019_000186.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0019_000231.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0020_000011.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0021_000101.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0021_000251.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0021_000401.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0021_000551.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0021_000701.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0021_000851.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0022_000128.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0023_000001.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0023_000551.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0023_000601.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0024_000101.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0024_000151.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0024_000201.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0025_000101.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0026_000001.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0026_000101.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0028_000151.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0029_000001.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0030_000100.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0031_000063.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0032_000001.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0033_000106.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0033_000111.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0033_000116.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0035_000051.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0037_000101.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0038_000001.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0038_000133.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0039_000201.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0040_000001.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0041_000151.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0042_000101.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0043_000066.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0045_000301.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0046_000001.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0046_000041.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0047_000051.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0048_000006.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0048_000161.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0049_000101.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0050_000109.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0055_000051.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0055_000151.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0056_000001.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0057_000051.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0058_000051.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0058_000151.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0058_000301.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0059_000051.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0060_000083.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0061_000074.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0062_000001.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0062_000051.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0062_000061.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0062_000076.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0062_000091.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0062_000106.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0063_000201.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0063_000256.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0064_000001.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0066_000001.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0068_000001.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0069_000251.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0070_000051.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0071_000051.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0072_000001.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0074_000001.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0077_000001.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0078_000251.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0079_000301.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0080_000051.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0081_000001.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0081_000151.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0082_000101.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0082_000146.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0082_000151.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0082_000161.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0082_000176.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0082_000191.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0082_000206.txt  \n",
            "  inflating: dataset/labels/val/I1_2009_12_14_drive_0082_000221.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bdef354",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bdef354",
        "outputId": "018cd34a-6085-4bd1-e01c-084c8cd81ee4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=/content/yolov5/yolov5s.pt, cfg=, data=/content/dataset.yml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=100, batch_size=20, imgsz=320, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
            "YOLOv5 🚀 v7.0-47-g2370a55 Python-3.8.16 torch-1.13.0+cu116 CPU\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "Overriding model.yaml nc=80 with nc=16\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     56637  models.yolo.Detect                      [16, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "Model summary: 214 layers, 7062781 parameters, 7062781 gradients, 16.1 GFLOPs\n",
            "\n",
            "Transferred 343/349 items from /content/yolov5/yolov5s.pt\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.00046875), 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/yolov5/dataset/labels/train.cache... 200 images, 0 backgrounds, 0 corrupt: 100% 200/200 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.0GB ram): 100% 200/200 [00:01<00:00, 107.14it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolov5/dataset/labels/val.cache... 88 images, 0 backgrounds, 0 corrupt: 100% 88/88 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB ram): 100% 88/88 [00:01<00:00, 74.02it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.81 anchors/target, 0.998 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
            "Plotting labels to runs/train/exp2/labels.jpg... \n",
            "Image sizes 320 train, 320 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/exp2\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       0/99         0G     0.1282     0.0247    0.07608        167        320: 100% 10/10 [01:17<00:00,  7.77s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:05<00:00,  1.68s/it]\n",
            "                   all         88        500    0.00305     0.0227    0.00169   0.000359\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       1/99         0G     0.1191    0.02765    0.06234        162        320: 100% 10/10 [01:13<00:00,  7.30s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.63s/it]\n",
            "                   all         88        500     0.0511     0.0643     0.0114    0.00274\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       2/99         0G     0.1082    0.03285    0.04581        138        320: 100% 10/10 [01:13<00:00,  7.31s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:05<00:00,  1.70s/it]\n",
            "                   all         88        500      0.528     0.0249     0.0133    0.00309\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       3/99         0G     0.1012    0.03393    0.03512        148        320: 100% 10/10 [01:12<00:00,  7.20s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:05<00:00,  1.87s/it]\n",
            "                   all         88        500      0.605      0.145     0.0568     0.0181\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       4/99         0G    0.09402    0.03362    0.02916        126        320: 100% 10/10 [01:11<00:00,  7.14s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:08<00:00,  2.80s/it]\n",
            "                   all         88        500      0.623      0.166     0.0969     0.0224\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       5/99         0G    0.09065    0.03143    0.02217        132        320: 100% 10/10 [01:14<00:00,  7.47s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0% 0/3 [00:00<?, ?it/s]WARNING ⚠️ NMS time limit 2.500s exceeded\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95:  33% 1/3 [00:04<00:08,  4.48s/it]WARNING ⚠️ NMS time limit 2.500s exceeded\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:10<00:00,  3.42s/it]\n",
            "                   all         88        500      0.725      0.149      0.164      0.045\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       6/99         0G    0.08994    0.02993    0.01995        119        320: 100% 10/10 [01:13<00:00,  7.31s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95:   0% 0/3 [00:00<?, ?it/s]WARNING ⚠️ NMS time limit 2.500s exceeded\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:10<00:00,  3.34s/it]\n",
            "                   all         88        500      0.199      0.317      0.171     0.0402\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       7/99         0G    0.08816    0.02921    0.01794        128        320: 100% 10/10 [01:12<00:00,  7.28s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:08<00:00,  2.88s/it]\n",
            "                   all         88        500      0.195      0.358      0.184     0.0473\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       8/99         0G    0.08463    0.02934    0.01539        126        320: 100% 10/10 [01:12<00:00,  7.28s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:07<00:00,  2.45s/it]\n",
            "                   all         88        500      0.226      0.359      0.176     0.0447\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       9/99         0G    0.08463    0.02763     0.0124        134        320: 100% 10/10 [01:12<00:00,  7.29s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:06<00:00,  2.16s/it]\n",
            "                   all         88        500      0.198      0.479      0.172     0.0469\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      10/99         0G    0.08463    0.02783    0.01139        141        320: 100% 10/10 [01:12<00:00,  7.24s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:05<00:00,  1.96s/it]\n",
            "                   all         88        500      0.328      0.411      0.321     0.0841\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      11/99         0G    0.07763    0.02673    0.01065        148        320: 100% 10/10 [01:11<00:00,  7.19s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:05<00:00,  1.90s/it]\n",
            "                   all         88        500      0.208      0.391      0.169     0.0446\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      12/99         0G    0.07962    0.02562    0.01006        149        320: 100% 10/10 [01:15<00:00,  7.59s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:05<00:00,  1.83s/it]\n",
            "                   all         88        500      0.343      0.451        0.3     0.0871\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      13/99         0G    0.07297    0.02949   0.009202        147        320: 100% 10/10 [01:13<00:00,  7.34s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:05<00:00,  1.91s/it]\n",
            "                   all         88        500       0.33      0.415      0.265      0.076\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      14/99         0G    0.07281    0.02582   0.009205        113        320: 100% 10/10 [01:12<00:00,  7.28s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:05<00:00,  1.77s/it]\n",
            "                   all         88        500      0.347      0.455      0.348      0.119\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      15/99         0G    0.06959    0.02642   0.009048        130        320: 100% 10/10 [01:13<00:00,  7.34s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:05<00:00,  1.73s/it]\n",
            "                   all         88        500      0.342      0.534      0.366      0.112\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      16/99         0G    0.06707     0.0269   0.008834        153        320: 100% 10/10 [01:13<00:00,  7.32s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:05<00:00,  1.84s/it]\n",
            "                   all         88        500      0.369      0.496      0.355      0.118\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      17/99         0G    0.06372    0.02749   0.008122        130        320: 100% 10/10 [01:14<00:00,  7.42s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:05<00:00,  1.76s/it]\n",
            "                   all         88        500      0.332      0.406      0.325      0.104\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      18/99         0G    0.06787    0.02785   0.008547        147        320: 100% 10/10 [01:13<00:00,  7.37s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.63s/it]\n",
            "                   all         88        500       0.47      0.577      0.492      0.153\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      19/99         0G    0.06322    0.02736    0.00772        171        320: 100% 10/10 [01:13<00:00,  7.30s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:05<00:00,  1.70s/it]\n",
            "                   all         88        500       0.36      0.521      0.372      0.112\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      20/99         0G    0.06154    0.02618   0.007325        110        320: 100% 10/10 [01:16<00:00,  7.64s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.65s/it]\n",
            "                   all         88        500       0.35      0.514      0.386      0.126\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      21/99         0G    0.06319    0.02497   0.007137        128        320: 100% 10/10 [01:13<00:00,  7.34s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.65s/it]\n",
            "                   all         88        500      0.459       0.51      0.444      0.153\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      22/99         0G    0.05857    0.02531   0.007743        142        320: 100% 10/10 [01:13<00:00,  7.39s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.64s/it]\n",
            "                   all         88        500      0.481      0.552      0.514      0.199\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      23/99         0G    0.05896    0.02689   0.006247        138        320: 100% 10/10 [01:15<00:00,  7.51s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.66s/it]\n",
            "                   all         88        500       0.45      0.547       0.47      0.162\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      24/99         0G    0.06068    0.02529   0.006175        151        320: 100% 10/10 [01:14<00:00,  7.44s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.61s/it]\n",
            "                   all         88        500      0.592      0.567       0.56      0.189\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      25/99         0G    0.05659    0.02597   0.007273        131        320: 100% 10/10 [01:14<00:00,  7.44s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.62s/it]\n",
            "                   all         88        500      0.509       0.51      0.476      0.153\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      26/99         0G    0.05778    0.02662   0.006455        134        320: 100% 10/10 [01:14<00:00,  7.46s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.61s/it]\n",
            "                   all         88        500      0.581      0.536      0.581      0.225\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      27/99         0G    0.05431    0.02572   0.006282        155        320: 100% 10/10 [01:14<00:00,  7.41s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.59s/it]\n",
            "                   all         88        500      0.443      0.604      0.493      0.188\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      28/99         0G    0.05479    0.02503   0.006758        106        320: 100% 10/10 [01:13<00:00,  7.32s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.58s/it]\n",
            "                   all         88        500      0.575      0.542      0.586      0.206\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      29/99         0G    0.05493    0.02497   0.005744        111        320: 100% 10/10 [01:14<00:00,  7.41s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.59s/it]\n",
            "                   all         88        500      0.542      0.586      0.555      0.199\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      30/99         0G     0.0561    0.02437   0.007014        146        320: 100% 10/10 [01:13<00:00,  7.35s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.55s/it]\n",
            "                   all         88        500      0.706      0.638      0.689      0.268\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      31/99         0G    0.05467    0.02662   0.005697        132        320: 100% 10/10 [01:13<00:00,  7.38s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.64s/it]\n",
            "                   all         88        500      0.673      0.522      0.595      0.181\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      32/99         0G    0.05346    0.02602   0.006337        139        320: 100% 10/10 [01:14<00:00,  7.44s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.55s/it]\n",
            "                   all         88        500      0.777       0.62      0.718      0.272\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      33/99         0G    0.05418    0.02618    0.00599        142        320: 100% 10/10 [01:18<00:00,  7.83s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:05<00:00,  1.79s/it]\n",
            "                   all         88        500      0.689      0.571      0.624      0.215\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      34/99         0G    0.05316    0.02681   0.005555        141        320: 100% 10/10 [01:17<00:00,  7.72s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.60s/it]\n",
            "                   all         88        500      0.745      0.634      0.696      0.241\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      35/99         0G    0.05229    0.02695   0.005577        137        320: 100% 10/10 [01:16<00:00,  7.66s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.61s/it]\n",
            "                   all         88        500      0.512      0.611      0.557      0.201\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      36/99         0G    0.05278     0.0245   0.005474        141        320: 100% 10/10 [01:14<00:00,  7.43s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.64s/it]\n",
            "                   all         88        500      0.764      0.651       0.72      0.274\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      37/99         0G    0.05012    0.02536   0.005116        137        320: 100% 10/10 [01:16<00:00,  7.64s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.56s/it]\n",
            "                   all         88        500       0.77      0.652      0.719      0.272\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      38/99         0G    0.05026     0.0242   0.005542        128        320: 100% 10/10 [01:12<00:00,  7.28s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.53s/it]\n",
            "                   all         88        500      0.739      0.634        0.7      0.276\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      39/99         0G    0.04904    0.02464   0.005301        158        320: 100% 10/10 [01:13<00:00,  7.30s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.52s/it]\n",
            "                   all         88        500      0.732      0.652      0.685      0.265\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      40/99         0G    0.04984    0.02547    0.00487        143        320: 100% 10/10 [01:12<00:00,  7.27s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.55s/it]\n",
            "                   all         88        500      0.759      0.606      0.701      0.258\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      41/99         0G    0.04881    0.02366   0.004569        143        320: 100% 10/10 [01:13<00:00,  7.31s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.54s/it]\n",
            "                   all         88        500      0.784      0.613      0.706       0.27\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      42/99         0G    0.05057    0.02444   0.005267        120        320: 100% 10/10 [01:12<00:00,  7.29s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.54s/it]\n",
            "                   all         88        500      0.769      0.687       0.74      0.286\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      43/99         0G    0.04952    0.02436   0.005005        132        320: 100% 10/10 [01:13<00:00,  7.31s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.53s/it]\n",
            "                   all         88        500      0.763      0.627      0.709      0.262\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      44/99         0G    0.04808    0.02454   0.004772        106        320: 100% 10/10 [01:12<00:00,  7.29s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.52s/it]\n",
            "                   all         88        500      0.775      0.609      0.694      0.241\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      45/99         0G    0.04689    0.02401   0.005112        145        320: 100% 10/10 [01:13<00:00,  7.32s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.52s/it]\n",
            "                   all         88        500      0.828      0.602      0.717       0.27\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      46/99         0G    0.04716    0.02405    0.00472        124        320: 100% 10/10 [01:12<00:00,  7.29s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.54s/it]\n",
            "                   all         88        500      0.801      0.626      0.726      0.286\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      47/99         0G    0.04456    0.02437    0.00417        178        320: 100% 10/10 [01:13<00:00,  7.35s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.54s/it]\n",
            "                   all         88        500      0.712        0.6      0.656      0.236\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      48/99         0G    0.04777    0.02499   0.004317        168        320: 100% 10/10 [01:13<00:00,  7.35s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.53s/it]\n",
            "                   all         88        500      0.778      0.674      0.744      0.288\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      49/99         0G      0.047    0.02328   0.004643        123        320: 100% 10/10 [01:13<00:00,  7.34s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.55s/it]\n",
            "                   all         88        500      0.766      0.675      0.737      0.281\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      50/99         0G    0.04454    0.02437   0.004444        144        320: 100% 10/10 [01:14<00:00,  7.41s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.53s/it]\n",
            "                   all         88        500      0.799      0.617       0.71      0.279\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      51/99         0G    0.04544     0.0242   0.004442        130        320: 100% 10/10 [01:16<00:00,  7.70s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.52s/it]\n",
            "                   all         88        500      0.803      0.644      0.731      0.284\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      52/99         0G    0.04583    0.02318   0.004398        139        320: 100% 10/10 [01:13<00:00,  7.39s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.52s/it]\n",
            "                   all         88        500      0.748      0.677      0.732      0.273\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      53/99         0G    0.04448    0.02259   0.004125        144        320: 100% 10/10 [01:14<00:00,  7.42s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.54s/it]\n",
            "                   all         88        500      0.736      0.594      0.677      0.244\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      54/99         0G    0.04572    0.02339   0.003673        131        320: 100% 10/10 [01:13<00:00,  7.35s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.55s/it]\n",
            "                   all         88        500      0.788      0.675      0.753       0.31\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      55/99         0G    0.04388    0.02371   0.004039        155        320: 100% 10/10 [01:13<00:00,  7.36s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.55s/it]\n",
            "                   all         88        500      0.771      0.631      0.727      0.278\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      56/99         0G    0.04333    0.02274   0.003644        117        320: 100% 10/10 [01:13<00:00,  7.36s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.52s/it]\n",
            "                   all         88        500      0.835      0.629      0.731      0.294\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      57/99         0G     0.0455    0.02451   0.004012        162        320: 100% 10/10 [01:13<00:00,  7.35s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.55s/it]\n",
            "                   all         88        500       0.81      0.619      0.725      0.288\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      58/99         0G    0.04257    0.02263   0.004328        142        320: 100% 10/10 [01:13<00:00,  7.33s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.52s/it]\n",
            "                   all         88        500      0.818      0.621      0.725      0.292\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      59/99         0G    0.04365    0.02331   0.004526        118        320: 100% 10/10 [01:14<00:00,  7.41s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.52s/it]\n",
            "                   all         88        500      0.778      0.588      0.687      0.241\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      60/99         0G    0.04316    0.02397   0.003523        152        320: 100% 10/10 [01:13<00:00,  7.38s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.54s/it]\n",
            "                   all         88        500      0.806      0.643      0.735      0.286\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      61/99         0G    0.04196    0.02232   0.003705        134        320: 100% 10/10 [01:13<00:00,  7.39s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.53s/it]\n",
            "                   all         88        500      0.827      0.631       0.73      0.297\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      62/99         0G    0.04074    0.02295   0.003735        145        320: 100% 10/10 [01:13<00:00,  7.38s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.54s/it]\n",
            "                   all         88        500      0.786      0.637      0.714      0.287\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      63/99         0G    0.04194    0.02271   0.003677        131        320: 100% 10/10 [01:14<00:00,  7.41s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.55s/it]\n",
            "                   all         88        500      0.824      0.628      0.721      0.287\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      64/99         0G    0.04141    0.02126   0.003559        115        320: 100% 10/10 [01:13<00:00,  7.36s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.54s/it]\n",
            "                   all         88        500      0.821      0.605      0.714      0.275\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      65/99         0G    0.04058    0.02352   0.003462        120        320: 100% 10/10 [01:13<00:00,  7.35s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.52s/it]\n",
            "                   all         88        500      0.792      0.686      0.748      0.301\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      66/99         0G    0.04024    0.02267    0.00359        132        320: 100% 10/10 [01:13<00:00,  7.38s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.55s/it]\n",
            "                   all         88        500      0.805      0.646      0.747      0.304\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      67/99         0G    0.04062    0.02236   0.003265        151        320: 100% 10/10 [01:13<00:00,  7.37s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.54s/it]\n",
            "                   all         88        500      0.779      0.673      0.744      0.302\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      68/99         0G    0.03984    0.02337   0.003208        127        320: 100% 10/10 [01:14<00:00,  7.41s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.54s/it]\n",
            "                   all         88        500      0.764      0.664      0.732      0.279\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      69/99         0G    0.04048    0.02239   0.003229        110        320: 100% 10/10 [01:14<00:00,  7.44s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.53s/it]\n",
            "                   all         88        500      0.814      0.653      0.746      0.302\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      70/99         0G    0.03919    0.02294   0.003095        163        320: 100% 10/10 [01:13<00:00,  7.39s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.51s/it]\n",
            "                   all         88        500      0.766      0.689       0.75       0.29\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      71/99         0G     0.0395    0.02213   0.002944        155        320: 100% 10/10 [01:14<00:00,  7.43s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.54s/it]\n",
            "                   all         88        500      0.783        0.7      0.755      0.303\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      72/99         0G    0.03962    0.02337    0.00347        140        320: 100% 10/10 [01:14<00:00,  7.43s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.53s/it]\n",
            "                   all         88        500      0.787       0.68      0.753      0.303\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      73/99         0G    0.03879    0.02225      0.003        113        320: 100% 10/10 [01:13<00:00,  7.38s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.50s/it]\n",
            "                   all         88        500      0.789      0.696      0.758      0.309\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      74/99         0G    0.03888    0.02212   0.003062        164        320: 100% 10/10 [01:13<00:00,  7.36s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.54s/it]\n",
            "                   all         88        500       0.81      0.655      0.753      0.304\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      75/99         0G    0.03865    0.02255   0.003146        131        320: 100% 10/10 [01:14<00:00,  7.43s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.53s/it]\n",
            "                   all         88        500      0.794      0.674      0.742      0.298\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      76/99         0G    0.03688    0.02245   0.002914        147        320: 100% 10/10 [01:13<00:00,  7.39s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.52s/it]\n",
            "                   all         88        500      0.781      0.701      0.754      0.309\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      77/99         0G    0.03776    0.02287   0.003095        111        320: 100% 10/10 [01:18<00:00,  7.86s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.62s/it]\n",
            "                   all         88        500      0.825      0.662      0.752      0.307\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      78/99         0G    0.03784    0.02126   0.003368        141        320: 100% 10/10 [01:14<00:00,  7.49s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.55s/it]\n",
            "                   all         88        500      0.832      0.675      0.765      0.313\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      79/99         0G     0.0377    0.02212   0.002729        125        320: 100% 10/10 [01:17<00:00,  7.80s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.58s/it]\n",
            "                   all         88        500       0.83      0.674      0.764      0.313\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      80/99         0G    0.03711    0.02173   0.003341        118        320: 100% 10/10 [01:19<00:00,  7.98s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.63s/it]\n",
            "                   all         88        500      0.828      0.668      0.757      0.311\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      81/99         0G    0.03716    0.02183   0.002876        115        320: 100% 10/10 [01:17<00:00,  7.76s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.60s/it]\n",
            "                   all         88        500      0.822      0.658      0.754      0.311\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      82/99         0G    0.03725    0.02135   0.002788        126        320: 100% 10/10 [01:16<00:00,  7.69s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.56s/it]\n",
            "                   all         88        500      0.818      0.652      0.755      0.309\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      83/99         0G    0.03734    0.02241   0.003168        151        320: 100% 10/10 [01:17<00:00,  7.70s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.58s/it]\n",
            "                   all         88        500      0.803      0.667      0.742      0.299\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      84/99         0G    0.03646    0.02163   0.002996        137        320: 100% 10/10 [01:17<00:00,  7.79s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.61s/it]\n",
            "                   all         88        500      0.812      0.662      0.749      0.301\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      85/99         0G    0.03542     0.0222   0.002947        122        320: 100% 10/10 [01:16<00:00,  7.64s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.62s/it]\n",
            "                   all         88        500       0.81      0.663      0.737      0.303\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      86/99         0G    0.03647     0.0218   0.002812        112        320: 100% 10/10 [01:19<00:00,  7.97s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.54s/it]\n",
            "                   all         88        500      0.818       0.66      0.736      0.303\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      87/99         0G    0.03578    0.02108   0.002901        126        320: 100% 10/10 [01:14<00:00,  7.43s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.56s/it]\n",
            "                   all         88        500      0.837      0.643      0.743      0.304\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      88/99         0G    0.03596    0.02191    0.00252        142        320: 100% 10/10 [01:14<00:00,  7.41s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.51s/it]\n",
            "                   all         88        500      0.839      0.659      0.761      0.307\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      89/99         0G    0.03695    0.02159   0.002697        133        320: 100% 10/10 [01:14<00:00,  7.43s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.52s/it]\n",
            "                   all         88        500      0.841      0.658      0.756      0.306\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      90/99         0G    0.03432    0.02122   0.002494        144        320: 100% 10/10 [01:14<00:00,  7.47s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.53s/it]\n",
            "                   all         88        500      0.802      0.671       0.75      0.309\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      91/99         0G    0.03562    0.02223   0.002797        143        320: 100% 10/10 [01:13<00:00,  7.39s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.53s/it]\n",
            "                   all         88        500      0.817       0.68      0.756      0.312\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      92/99         0G    0.03559    0.02215    0.00242        132        320: 100% 10/10 [01:14<00:00,  7.42s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.50s/it]\n",
            "                   all         88        500      0.815      0.681      0.756      0.311\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      93/99         0G    0.03549    0.02112    0.00253        114        320: 100% 10/10 [01:14<00:00,  7.42s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.51s/it]\n",
            "                   all         88        500       0.81      0.686      0.754      0.311\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      94/99         0G    0.03471     0.0218   0.002593        123        320: 100% 10/10 [01:12<00:00,  7.30s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.52s/it]\n",
            "                   all         88        500      0.806      0.676      0.744      0.309\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      95/99         0G    0.03405    0.02077   0.002477        142        320: 100% 10/10 [01:13<00:00,  7.36s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.50s/it]\n",
            "                   all         88        500       0.81      0.675       0.75      0.311\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      96/99         0G    0.03497    0.02146   0.002399        114        320: 100% 10/10 [01:13<00:00,  7.34s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.50s/it]\n",
            "                   all         88        500      0.817      0.667       0.75      0.314\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      97/99         0G    0.03425    0.02138   0.002239        127        320: 100% 10/10 [01:13<00:00,  7.34s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.50s/it]\n",
            "                   all         88        500      0.826       0.68      0.755       0.31\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      98/99         0G    0.03482    0.02165   0.002377        131        320: 100% 10/10 [01:13<00:00,  7.37s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:04<00:00,  1.52s/it]\n",
            "                   all         88        500      0.832      0.667      0.753      0.313\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      99/99         0G    0.03398    0.02114   0.002258         99        320: 100% 10/10 [01:13<00:00,  7.37s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:06<00:00,  2.10s/it]\n",
            "                   all         88        500      0.831      0.666       0.75      0.313\n",
            "\n",
            "100 epochs completed in 2.214 hours.\n",
            "Optimizer stripped from runs/train/exp2/weights/last.pt, 14.3MB\n",
            "Optimizer stripped from runs/train/exp2/weights/best.pt, 14.3MB\n",
            "\n",
            "Validating runs/train/exp2/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7053277 parameters, 0 gradients, 15.9 GFLOPs\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:05<00:00,  1.70s/it]\n",
            "                   all         88        500      0.833      0.678      0.767      0.313\n",
            "                person         88        259      0.769      0.758      0.789        0.3\n",
            "               vehicle         88        241      0.897      0.598      0.744      0.327\n",
            "Results saved to \u001b[1mruns/train/exp2\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python /content/yolov5/train.py --img 320 --batch 20 --epochs 100 --data /content/dataset.yml --weights /content/yolov5/yolov5s.pt --cache"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dfce6d37",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfce6d37",
        "outputId": "53415a83-2a51-442b-f157-367153468fb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/ultralytics/yolov5/zipball/master\" to /root/.cache/torch/hub/master.zip\n",
            "YOLOv5 🚀 2022-12-24 Python-3.8.16 torch-1.13.0+cu116 CPU\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '/usr/local/lib/python3.8/dist-packages/cycler-0.11.0.dist-info/METADATA'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fusing layers... \n",
            "Model summary: 157 layers, 7053277 parameters, 0 gradients, 15.9 GFLOPs\n",
            "Adding AutoShape... \n"
          ]
        }
      ],
      "source": [
        "model = torch.hub.load('ultralytics/yolov5', 'custom', path='/content/yolov5/runs/train/exp2/weights/best.pt',force_reload=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af5cb4cb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "af5cb4cb",
        "outputId": "8ed3dbb2-549d-46b7-c1ce-58670f620f1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['/content/yolov5/runs/train/exp2/weights/best.pt'], source=/content/yolov5/test, data=data/coco128.yaml, imgsz=[320, 320], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 🚀 v7.0-47-g2370a55 Python-3.8.16 torch-1.13.0+cu116 CPU\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7053277 parameters, 0 gradients, 15.9 GFLOPs\n",
            "image 1/144 /content/yolov5/test/I1_2009_12_14_drive_0082_000231.png: 128x320 17 persons, 65.4ms\n",
            "image 2/144 /content/yolov5/test/I1_2009_12_14_drive_0082_000256.png: 128x320 9 persons, 58.6ms\n",
            "image 3/144 /content/yolov5/test/I1_2009_12_14_drive_0082_000271.png: 128x320 9 persons, 66.8ms\n",
            "image 4/144 /content/yolov5/test/I1_2009_12_14_drive_0082_000291.png: 128x320 4 persons, 1 vehicle, 59.5ms\n",
            "image 5/144 /content/yolov5/test/I1_2009_12_14_drive_0082_000716.png: 128x320 1 person, 3 vehicles, 48.8ms\n",
            "image 6/144 /content/yolov5/test/I1_2009_12_14_drive_0083_000110.png: 128x320 1 person, 2 vehicles, 54.0ms\n",
            "image 7/144 /content/yolov5/test/I1_2009_12_14_drive_0086_000051.png: 128x320 6 persons, 54.1ms\n",
            "image 8/144 /content/yolov5/test/I1_2009_12_14_drive_0086_000101.png: 128x320 8 persons, 52.4ms\n",
            "image 9/144 /content/yolov5/test/I1_2009_12_14_drive_0086_000201.png: 128x320 3 persons, 2 vehicles, 56.2ms\n",
            "image 10/144 /content/yolov5/test/I1_2009_12_14_drive_0088_000051.png: 128x320 3 vehicles, 56.8ms\n",
            "image 11/144 /content/yolov5/test/I1_2009_12_14_drive_0088_000101.png: 128x320 5 vehicles, 50.1ms\n",
            "image 12/144 /content/yolov5/test/I1_2009_12_14_drive_0089_000101.png: 128x320 4 vehicles, 56.8ms\n",
            "image 13/144 /content/yolov5/test/I1_2009_12_14_drive_0090_000151.png: 128x320 4 vehicles, 59.8ms\n",
            "image 14/144 /content/yolov5/test/I1_2009_12_14_drive_0092_000051.png: 128x320 5 vehicles, 53.2ms\n",
            "image 15/144 /content/yolov5/test/I1_2009_12_14_drive_0093_000001.png: 128x320 3 vehicles, 60.6ms\n",
            "image 16/144 /content/yolov5/test/I1_2009_12_14_drive_0095_000101.png: 128x320 3 vehicles, 56.9ms\n",
            "image 17/144 /content/yolov5/test/I1_2009_12_14_drive_0098_000120.png: 128x320 7 vehicles, 50.9ms\n",
            "image 18/144 /content/yolov5/test/I1_2009_12_14_drive_0101_000001.png: 128x320 2 persons, 1 vehicle, 52.1ms\n",
            "image 19/144 /content/yolov5/test/I1_2009_12_14_drive_0101_000051.png: 128x320 3 persons, 1 vehicle, 50.4ms\n",
            "image 20/144 /content/yolov5/test/I1_2009_12_14_drive_0101_000103.png: 128x320 6 vehicles, 48.8ms\n",
            "image 21/144 /content/yolov5/test/I1_2009_12_14_drive_0102_000001.png: 128x320 5 vehicles, 52.3ms\n",
            "image 22/144 /content/yolov5/test/I1_2009_12_14_drive_0102_000259.png: 128x320 2 persons, 1 vehicle, 48.4ms\n",
            "image 23/144 /content/yolov5/test/I1_2009_12_14_drive_0103_000016.png: 128x320 1 person, 1 vehicle, 48.7ms\n",
            "image 24/144 /content/yolov5/test/I1_2010_03_04_drive_0002_000051.png: 96x320 1 person, 44.8ms\n",
            "image 25/144 /content/yolov5/test/I1_2010_03_04_drive_0002_000101.png: 96x320 3 persons, 45.4ms\n",
            "image 26/144 /content/yolov5/test/I1_2010_03_04_drive_0003_000001.png: 96x320 4 vehicles, 46.1ms\n",
            "image 27/144 /content/yolov5/test/I1_2010_03_04_drive_0003_000201.png: 96x320 6 vehicles, 42.7ms\n",
            "image 28/144 /content/yolov5/test/I1_2010_03_04_drive_0004_000101.png: 96x320 2 vehicles, 48.1ms\n",
            "image 29/144 /content/yolov5/test/I1_2010_03_04_drive_0004_000901.png: 96x320 6 vehicles, 41.7ms\n",
            "image 30/144 /content/yolov5/test/I1_2010_03_04_drive_0004_001001.png: 96x320 3 vehicles, 39.5ms\n",
            "image 31/144 /content/yolov5/test/I1_2010_03_04_drive_0004_001051.png: 96x320 1 person, 3 vehicles, 39.5ms\n",
            "image 32/144 /content/yolov5/test/I1_2010_03_04_drive_0006_000001.png: 96x320 4 vehicles, 39.7ms\n",
            "image 33/144 /content/yolov5/test/I1_2010_03_04_drive_0007_000051.png: 96x320 1 vehicle, 40.6ms\n",
            "image 34/144 /content/yolov5/test/I1_2010_03_04_drive_0008_000101.png: 96x320 2 persons, 1 vehicle, 43.4ms\n",
            "image 35/144 /content/yolov5/test/I1_2010_03_04_drive_0008_000116.png: 96x320 3 vehicles, 39.0ms\n",
            "image 36/144 /content/yolov5/test/I1_2010_03_04_drive_0008_000171.png: 96x320 2 persons, 1 vehicle, 45.2ms\n",
            "image 37/144 /content/yolov5/test/I1_2010_03_04_drive_0008_000176.png: 96x320 3 persons, 1 vehicle, 41.4ms\n",
            "image 38/144 /content/yolov5/test/I1_2010_03_04_drive_0009_000186.png: 96x320 3 persons, 1 vehicle, 40.3ms\n",
            "image 39/144 /content/yolov5/test/I1_2010_03_04_drive_0009_000236.png: 96x320 2 vehicles, 44.7ms\n",
            "image 40/144 /content/yolov5/test/I1_2010_03_04_drive_0010_000051.png: 96x320 3 vehicles, 43.5ms\n",
            "image 41/144 /content/yolov5/test/I1_2010_03_04_drive_0010_000066.png: 96x320 2 persons, 2 vehicles, 40.2ms\n",
            "image 42/144 /content/yolov5/test/I1_2010_03_04_drive_0010_000076.png: 96x320 2 persons, 2 vehicles, 43.3ms\n",
            "image 43/144 /content/yolov5/test/I1_2010_03_04_drive_0010_000086.png: 96x320 2 persons, 2 vehicles, 44.3ms\n",
            "image 44/144 /content/yolov5/test/I1_2010_03_04_drive_0011_000006.png: 96x320 1 person, 43.7ms\n",
            "image 45/144 /content/yolov5/test/I1_2010_03_04_drive_0012_000051.png: 96x320 1 vehicle, 44.1ms\n",
            "image 46/144 /content/yolov5/test/I1_2010_03_04_drive_0013_000001.png: 96x320 2 persons, 2 vehicles, 46.6ms\n",
            "image 47/144 /content/yolov5/test/I1_2010_03_04_drive_0013_000046.png: 96x320 2 vehicles, 61.5ms\n",
            "image 48/144 /content/yolov5/test/I1_2010_03_04_drive_0013_000151.png: 96x320 1 person, 3 vehicles, 41.8ms\n",
            "image 49/144 /content/yolov5/test/I1_2010_03_04_drive_0013_000301.png: 96x320 2 vehicles, 51.9ms\n",
            "image 50/144 /content/yolov5/test/I1_2010_03_04_drive_0013_000356.png: 96x320 4 persons, 42.1ms\n",
            "image 51/144 /content/yolov5/test/I1_2010_03_04_drive_0013_000400.png: 96x320 3 vehicles, 75.0ms\n",
            "image 52/144 /content/yolov5/test/I1_2010_03_04_drive_0014_000001.png: 96x320 4 vehicles, 46.4ms\n",
            "image 53/144 /content/yolov5/test/I1_2010_03_04_drive_0014_000101.png: 96x320 (no detections), 39.7ms\n",
            "image 54/144 /content/yolov5/test/I1_2010_03_04_drive_0014_000121.png: 96x320 2 persons, 1 vehicle, 43.0ms\n",
            "image 55/144 /content/yolov5/test/I1_2010_03_04_drive_0014_000156.png: 96x320 2 persons, 2 vehicles, 40.1ms\n",
            "image 56/144 /content/yolov5/test/I1_2010_03_04_drive_0014_000596.png: 96x320 6 vehicles, 42.5ms\n",
            "image 57/144 /content/yolov5/test/I1_2010_03_04_drive_0015_000101.png: 96x320 1 person, 41.3ms\n",
            "image 58/144 /content/yolov5/test/I1_2010_03_04_drive_0017_000151.png: 96x320 3 vehicles, 43.2ms\n",
            "image 59/144 /content/yolov5/test/I1_2010_03_04_drive_0017_000401.png: 96x320 1 person, 47.2ms\n",
            "image 60/144 /content/yolov5/test/I1_2010_03_04_drive_0018_000151.png: 96x320 3 vehicles, 41.9ms\n",
            "image 61/144 /content/yolov5/test/I1_2010_03_04_drive_0019_000306.png: 96x320 3 vehicles, 44.9ms\n",
            "image 62/144 /content/yolov5/test/I1_2010_03_04_drive_0020_000101.png: 96x320 4 vehicles, 45.1ms\n",
            "image 63/144 /content/yolov5/test/I1_2010_03_04_drive_0021_000401.png: 96x320 2 persons, 1 vehicle, 48.6ms\n",
            "image 64/144 /content/yolov5/test/I1_2010_03_04_drive_0021_000406.png: 96x320 2 persons, 3 vehicles, 42.2ms\n",
            "image 65/144 /content/yolov5/test/I1_2010_03_04_drive_0023_000021.png: 96x320 4 vehicles, 43.8ms\n",
            "image 66/144 /content/yolov5/test/I1_2010_03_04_drive_0023_000046.png: 96x320 2 persons, 2 vehicles, 43.3ms\n",
            "image 67/144 /content/yolov5/test/I1_2010_03_04_drive_0024_000101.png: 96x320 1 person, 2 vehicles, 49.6ms\n",
            "image 68/144 /content/yolov5/test/I1_2010_03_04_drive_0027_000051.png: 96x320 3 vehicles, 40.0ms\n",
            "image 69/144 /content/yolov5/test/I1_2010_03_04_drive_0027_000101.png: 96x320 5 vehicles, 46.7ms\n",
            "image 70/144 /content/yolov5/test/I1_2010_03_04_drive_0027_000121.png: 96x320 4 vehicles, 47.0ms\n",
            "image 71/144 /content/yolov5/test/I1_2010_03_04_drive_0028_000001.png: 96x320 2 vehicles, 43.5ms\n",
            "image 72/144 /content/yolov5/test/I1_2010_03_04_drive_0028_000051.png: 96x320 1 vehicle, 59.3ms\n",
            "image 73/144 /content/yolov5/test/I1_2010_03_04_drive_0029_000051.png: 96x320 2 vehicles, 42.1ms\n",
            "image 74/144 /content/yolov5/test/I1_2010_03_04_drive_0031_000001.png: 96x320 2 vehicles, 42.5ms\n",
            "image 75/144 /content/yolov5/test/I1_2010_03_04_drive_0031_000030.png: 96x320 4 vehicles, 46.8ms\n",
            "image 76/144 /content/yolov5/test/I1_2010_03_04_drive_0032_000201.png: 96x320 3 vehicles, 41.3ms\n",
            "image 77/144 /content/yolov5/test/I1_2010_03_04_drive_0033_000001.png: 96x320 1 vehicle, 44.1ms\n",
            "image 78/144 /content/yolov5/test/I1_2010_03_04_drive_0033_000051.png: 96x320 4 vehicles, 42.8ms\n",
            "image 79/144 /content/yolov5/test/I1_2010_03_04_drive_0033_000221.png: 96x320 3 vehicles, 42.0ms\n",
            "image 80/144 /content/yolov5/test/I1_2010_03_04_drive_0034_000107.png: 96x320 4 vehicles, 42.7ms\n",
            "image 81/144 /content/yolov5/test/I1_2010_03_04_drive_0035_000451.png: 96x320 3 vehicles, 40.0ms\n",
            "image 82/144 /content/yolov5/test/I1_2010_03_04_drive_0035_000470.png: 96x320 4 vehicles, 40.3ms\n",
            "image 83/144 /content/yolov5/test/I1_2010_03_04_drive_0038_000351.png: 96x320 4 vehicles, 42.2ms\n",
            "image 84/144 /content/yolov5/test/I1_2010_03_04_drive_0038_000413.png: 96x320 2 vehicles, 53.2ms\n",
            "image 85/144 /content/yolov5/test/I1_2010_03_04_drive_0039_000101.png: 96x320 3 vehicles, 42.6ms\n",
            "image 86/144 /content/yolov5/test/I1_2010_03_04_drive_0039_000301.png: 96x320 1 person, 4 vehicles, 43.7ms\n",
            "image 87/144 /content/yolov5/test/I1_2010_03_04_drive_0039_000501.png: 96x320 3 vehicles, 46.3ms\n",
            "image 88/144 /content/yolov5/test/I1_2010_03_04_drive_0040_000048.png: 96x320 3 vehicles, 43.4ms\n",
            "image 89/144 /content/yolov5/test/I1_2010_03_04_drive_0041_000449.png: 96x320 2 vehicles, 44.5ms\n",
            "image 90/144 /content/yolov5/test/I1_2010_03_04_drive_0042_000051.png: 96x320 3 vehicles, 47.5ms\n",
            "image 91/144 /content/yolov5/test/I1_2010_03_04_drive_0043_000001.png: 96x320 3 vehicles, 39.5ms\n",
            "image 92/144 /content/yolov5/test/I1_2010_03_05_drive_0006_000056.png: 96x320 1 person, 2 vehicles, 41.5ms\n",
            "image 93/144 /content/yolov5/test/I1_2010_03_05_drive_0006_000756.png: 96x320 1 person, 4 vehicles, 46.5ms\n",
            "image 94/144 /content/yolov5/test/I1_2010_03_05_drive_0006_000906.png: 96x320 2 vehicles, 40.3ms\n",
            "image 95/144 /content/yolov5/test/I1_2010_03_05_drive_0007_000151.png: 96x320 1 vehicle, 42.7ms\n",
            "image 96/144 /content/yolov5/test/I1_2010_03_05_drive_0009_000201.png: 96x320 2 vehicles, 49.3ms\n",
            "image 97/144 /content/yolov5/test/I1_2010_03_05_drive_0009_000251.png: 96x320 3 vehicles, 42.0ms\n",
            "image 98/144 /content/yolov5/test/I1_2010_03_05_drive_0012_000121.png: 96x320 2 persons, 1 vehicle, 40.0ms\n",
            "image 99/144 /content/yolov5/test/I1_2010_03_05_drive_0012_000126.png: 96x320 1 person, 1 vehicle, 39.8ms\n",
            "image 100/144 /content/yolov5/test/I1_2010_03_05_drive_0012_000166.png: 96x320 2 vehicles, 42.2ms\n",
            "image 101/144 /content/yolov5/test/I1_2010_03_05_drive_0012_000181.png: 96x320 1 person, 1 vehicle, 44.2ms\n",
            "image 102/144 /content/yolov5/test/I1_2010_03_05_drive_0013_000001.png: 96x320 1 person, 1 vehicle, 41.4ms\n",
            "image 103/144 /content/yolov5/test/I1_2010_03_05_drive_0013_000036.png: 96x320 3 vehicles, 41.9ms\n",
            "image 104/144 /content/yolov5/test/I1_2010_03_05_drive_0014_000096.png: 96x320 3 vehicles, 45.7ms\n",
            "image 105/144 /content/yolov5/test/I1_2010_03_05_drive_0014_000196.png: 96x320 5 vehicles, 85.1ms\n",
            "image 106/144 /content/yolov5/test/I1_2010_03_05_drive_0014_000221.png: 96x320 1 person, 3 vehicles, 42.7ms\n",
            "image 107/144 /content/yolov5/test/I1_2010_03_05_drive_0014_000276.png: 96x320 3 persons, 2 vehicles, 44.1ms\n",
            "image 108/144 /content/yolov5/test/I1_2010_03_05_drive_0015_000106.png: 96x320 3 persons, 39.9ms\n",
            "image 109/144 /content/yolov5/test/I1_2010_03_05_drive_0015_000131.png: 96x320 4 persons, 2 vehicles, 39.7ms\n",
            "image 110/144 /content/yolov5/test/I1_2010_03_05_drive_0015_000141.png: 96x320 3 persons, 1 vehicle, 45.9ms\n",
            "image 111/144 /content/yolov5/test/I1_2010_03_05_drive_0015_000151.png: 96x320 2 persons, 1 vehicle, 40.9ms\n",
            "image 112/144 /content/yolov5/test/I1_2010_03_05_drive_0015_000161.png: 96x320 1 person, 1 vehicle, 39.2ms\n",
            "image 113/144 /content/yolov5/test/I1_2010_03_05_drive_0015_000231.png: 96x320 1 person, 3 vehicles, 38.8ms\n",
            "image 114/144 /content/yolov5/test/I1_2010_03_05_drive_0015_000431.png: 96x320 4 persons, 1 vehicle, 42.8ms\n",
            "image 115/144 /content/yolov5/test/I1_2010_03_05_drive_0016_000151.png: 96x320 1 person, 1 vehicle, 38.1ms\n",
            "image 116/144 /content/yolov5/test/I1_2010_03_05_drive_0016_000166.png: 96x320 1 vehicle, 38.2ms\n",
            "image 117/144 /content/yolov5/test/I1_2010_03_05_drive_0016_000271.png: 96x320 3 persons, 3 vehicles, 44.4ms\n",
            "image 118/144 /content/yolov5/test/I1_2010_03_05_drive_0016_000281.png: 96x320 1 person, 2 vehicles, 44.1ms\n",
            "image 119/144 /content/yolov5/test/I1_2010_03_05_drive_0016_000296.png: 96x320 2 persons, 48.5ms\n",
            "image 120/144 /content/yolov5/test/I1_2010_03_05_drive_0017_000251.png: 96x320 3 vehicles, 45.1ms\n",
            "image 121/144 /content/yolov5/test/I1_2010_03_05_drive_0017_000366.png: 96x320 3 vehicles, 44.5ms\n",
            "image 122/144 /content/yolov5/test/I1_2010_03_05_drive_0017_000566.png: 96x320 1 person, 5 vehicles, 41.7ms\n",
            "image 123/144 /content/yolov5/test/I1_2010_03_05_drive_0017_000616.png: 96x320 1 person, 4 vehicles, 46.8ms\n",
            "image 124/144 /content/yolov5/test/I1_2010_03_05_drive_0017_000626.png: 96x320 2 persons, 2 vehicles, 46.8ms\n",
            "image 125/144 /content/yolov5/test/I1_2010_03_05_drive_0017_000726.png: 96x320 1 person, 3 vehicles, 44.6ms\n",
            "image 126/144 /content/yolov5/test/I1_2010_03_05_drive_0017_000736.png: 96x320 2 persons, 2 vehicles, 46.8ms\n",
            "image 127/144 /content/yolov5/test/I1_2010_03_05_drive_0017_000751.png: 96x320 3 persons, 3 vehicles, 41.8ms\n",
            "image 128/144 /content/yolov5/test/I1_2010_03_05_drive_0017_000756.png: 96x320 1 person, 2 vehicles, 47.7ms\n",
            "image 129/144 /content/yolov5/test/I1_2010_03_05_drive_0018_000051.png: 96x320 1 vehicle, 44.6ms\n",
            "image 130/144 /content/yolov5/test/I1_2010_03_05_drive_0018_000061.png: 96x320 2 persons, 1 vehicle, 54.4ms\n",
            "image 131/144 /content/yolov5/test/I1_2010_03_05_drive_0018_000071.png: 96x320 1 person, 42.3ms\n",
            "image 132/144 /content/yolov5/test/I1_2010_03_05_drive_0018_000076.png: 96x320 3 persons, 41.9ms\n",
            "image 133/144 /content/yolov5/test/I1_2010_03_05_drive_0018_000086.png: 96x320 3 persons, 41.2ms\n",
            "image 134/144 /content/yolov5/test/I1_2010_03_05_drive_0018_000121.png: 96x320 1 person, 39.7ms\n",
            "image 135/144 /content/yolov5/test/I1_2010_03_05_drive_0018_000391.png: 96x320 1 person, 1 vehicle, 42.8ms\n",
            "image 136/144 /content/yolov5/test/I1_2010_03_05_drive_0018_000401.png: 96x320 1 person, 39.7ms\n",
            "image 137/144 /content/yolov5/test/I1_2010_03_05_drive_0018_000406.png: 96x320 2 persons, 41.1ms\n",
            "image 138/144 /content/yolov5/test/I1_2010_03_05_drive_0018_000416.png: 96x320 1 person, 1 vehicle, 38.9ms\n",
            "image 139/144 /content/yolov5/test/I1_2010_03_05_drive_0018_000421.png: 96x320 2 persons, 38.8ms\n",
            "image 140/144 /content/yolov5/test/I1_2010_03_05_drive_0018_000431.png: 96x320 1 person, 2 vehicles, 45.2ms\n",
            "image 141/144 /content/yolov5/test/I1_2010_03_05_drive_0018_000466.png: 96x320 2 persons, 1 vehicle, 41.0ms\n",
            "image 142/144 /content/yolov5/test/I1_2010_03_05_drive_0018_000571.png: 96x320 1 person, 53.4ms\n",
            "image 143/144 /content/yolov5/test/I1_2010_03_05_drive_0018_000586.png: 96x320 1 person, 42.9ms\n",
            "image 144/144 /content/yolov5/test/I1_2010_03_05_drive_0018_000626.png: 96x320 2 persons, 41.1ms\n",
            "Speed: 0.3ms pre-process, 45.9ms inference, 0.7ms NMS per image at shape (1, 3, 320, 320)\n",
            "Results saved to \u001b[1mruns/detect/exp\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python /content/yolov5/detect.py --weights /content/yolov5/runs/train/exp2/weights/best.pt --img 320 --source /content/yolov5/test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c476fd1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c476fd1",
        "outputId": "2340ace5-5a73-4807-b823-712ff8d423b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/yolov5/runs/ (stored 0%)\n",
            "  adding: content/yolov5/runs/detect/ (stored 0%)\n",
            "  adding: content/yolov5/runs/detect/exp/ (stored 0%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_04_drive_0039_000301.png (deflated 17%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2009_12_14_drive_0086_000101.png (deflated 17%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_04_drive_0010_000066.png (deflated 17%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2009_12_14_drive_0086_000051.png (deflated 17%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_05_drive_0018_000061.png (deflated 16%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_05_drive_0006_000756.png (deflated 15%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_04_drive_0039_000101.png (deflated 17%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_05_drive_0007_000151.png (deflated 16%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_04_drive_0021_000401.png (deflated 18%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2009_12_14_drive_0098_000120.png (deflated 17%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_04_drive_0009_000236.png (deflated 19%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2009_12_14_drive_0093_000001.png (deflated 19%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_04_drive_0011_000006.png (deflated 19%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_04_drive_0010_000051.png (deflated 18%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_04_drive_0033_000221.png (deflated 19%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_04_drive_0032_000201.png (deflated 17%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_04_drive_0023_000046.png (deflated 18%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2009_12_14_drive_0103_000016.png (deflated 19%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_05_drive_0015_000131.png (deflated 15%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_05_drive_0018_000406.png (deflated 16%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_04_drive_0014_000001.png (deflated 19%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_04_drive_0003_000201.png (deflated 18%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_04_drive_0033_000001.png (deflated 17%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_04_drive_0041_000449.png (deflated 20%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_05_drive_0018_000416.png (deflated 16%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_05_drive_0015_000161.png (deflated 16%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_05_drive_0015_000431.png (deflated 16%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_05_drive_0017_000366.png (deflated 20%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_04_drive_0013_000151.png (deflated 19%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_05_drive_0017_000756.png (deflated 17%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_04_drive_0004_001001.png (deflated 19%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_04_drive_0023_000021.png (deflated 18%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_05_drive_0017_000251.png (deflated 18%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_05_drive_0018_000586.png (deflated 17%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_04_drive_0027_000101.png (deflated 18%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_05_drive_0015_000231.png (deflated 16%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_04_drive_0034_000107.png (deflated 18%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_04_drive_0013_000046.png (deflated 18%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_05_drive_0018_000071.png (deflated 16%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_04_drive_0004_000901.png (deflated 18%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_04_drive_0019_000306.png (deflated 17%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_05_drive_0014_000221.png (deflated 17%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_04_drive_0008_000176.png (deflated 18%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_04_drive_0038_000351.png (deflated 18%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2009_12_14_drive_0092_000051.png (deflated 17%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2009_12_14_drive_0082_000256.png (deflated 15%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_04_drive_0012_000051.png (deflated 18%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_05_drive_0016_000296.png (deflated 20%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_04_drive_0006_000001.png (deflated 18%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_04_drive_0039_000501.png (deflated 18%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_04_drive_0042_000051.png (deflated 20%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_04_drive_0008_000116.png (deflated 18%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_05_drive_0006_000056.png (deflated 16%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2009_12_14_drive_0102_000001.png (deflated 19%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_05_drive_0018_000401.png (deflated 16%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2009_12_14_drive_0088_000051.png (deflated 18%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_04_drive_0004_001051.png (deflated 18%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_05_drive_0014_000196.png (deflated 17%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_04_drive_0017_000401.png (deflated 19%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_05_drive_0018_000626.png (deflated 16%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_04_drive_0014_000101.png (deflated 20%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_04_drive_0013_000356.png (deflated 19%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_04_drive_0028_000001.png (deflated 17%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_04_drive_0008_000101.png (deflated 18%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_05_drive_0013_000036.png (deflated 17%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2009_12_14_drive_0086_000201.png (deflated 18%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_05_drive_0018_000051.png (deflated 17%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_05_drive_0014_000276.png (deflated 16%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_04_drive_0028_000051.png (deflated 17%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_05_drive_0012_000121.png (deflated 19%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_05_drive_0017_000736.png (deflated 17%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_04_drive_0013_000400.png (deflated 19%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_05_drive_0015_000151.png (deflated 16%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_04_drive_0013_000001.png (deflated 17%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_05_drive_0018_000121.png (deflated 17%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2009_12_14_drive_0095_000101.png (deflated 18%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_05_drive_0017_000751.png (deflated 16%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2009_12_14_drive_0082_000291.png (deflated 16%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_05_drive_0013_000001.png (deflated 19%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_05_drive_0018_000086.png (deflated 16%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_05_drive_0018_000431.png (deflated 16%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2009_12_14_drive_0101_000103.png (deflated 19%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_05_drive_0018_000421.png (deflated 16%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_04_drive_0004_000101.png (deflated 19%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_05_drive_0017_000726.png (deflated 17%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_05_drive_0017_000626.png (deflated 17%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_05_drive_0012_000166.png (deflated 17%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_04_drive_0010_000086.png (deflated 17%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2009_12_14_drive_0102_000259.png (deflated 19%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_05_drive_0018_000076.png (deflated 16%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_04_drive_0003_000001.png (deflated 18%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_04_drive_0020_000101.png (deflated 17%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2009_12_14_drive_0101_000001.png (deflated 19%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_04_drive_0038_000413.png (deflated 19%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_05_drive_0012_000181.png (deflated 18%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_04_drive_0043_000001.png (deflated 18%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_04_drive_0014_000596.png (deflated 18%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_05_drive_0016_000151.png (deflated 18%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_04_drive_0035_000470.png (deflated 18%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_05_drive_0009_000201.png (deflated 16%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2009_12_14_drive_0083_000110.png (deflated 18%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_04_drive_0002_000101.png (deflated 19%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_05_drive_0016_000281.png (deflated 17%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_04_drive_0009_000186.png (deflated 18%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2009_12_14_drive_0090_000151.png (deflated 17%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_05_drive_0017_000566.png (deflated 18%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_05_drive_0017_000616.png (deflated 18%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_05_drive_0009_000251.png (deflated 15%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_05_drive_0018_000466.png (deflated 16%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_04_drive_0002_000051.png (deflated 19%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_04_drive_0018_000151.png (deflated 17%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_04_drive_0029_000051.png (deflated 20%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_04_drive_0035_000451.png (deflated 18%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2009_12_14_drive_0089_000101.png (deflated 17%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_05_drive_0006_000906.png (deflated 16%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2009_12_14_drive_0082_000271.png (deflated 15%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_04_drive_0015_000101.png (deflated 20%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_04_drive_0007_000051.png (deflated 20%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_04_drive_0017_000151.png (deflated 19%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_04_drive_0024_000101.png (deflated 17%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_05_drive_0014_000096.png (deflated 18%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2009_12_14_drive_0082_000716.png (deflated 18%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_05_drive_0015_000141.png (deflated 15%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2009_12_14_drive_0101_000051.png (deflated 19%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_04_drive_0031_000030.png (deflated 18%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_05_drive_0018_000391.png (deflated 16%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_04_drive_0014_000156.png (deflated 19%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_04_drive_0013_000301.png (deflated 19%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_04_drive_0021_000406.png (deflated 17%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_04_drive_0040_000048.png (deflated 18%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_05_drive_0015_000106.png (deflated 16%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_04_drive_0008_000171.png (deflated 19%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_05_drive_0012_000126.png (deflated 18%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_04_drive_0027_000051.png (deflated 17%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_05_drive_0016_000271.png (deflated 16%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_05_drive_0016_000166.png (deflated 18%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2009_12_14_drive_0082_000231.png (deflated 14%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_04_drive_0027_000121.png (deflated 17%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_04_drive_0010_000076.png (deflated 17%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_04_drive_0033_000051.png (deflated 19%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2009_12_14_drive_0088_000101.png (deflated 19%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_04_drive_0014_000121.png (deflated 19%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_05_drive_0018_000571.png (deflated 17%)\n",
            "  adding: content/yolov5/runs/detect/exp/I1_2010_03_04_drive_0031_000001.png (deflated 19%)\n",
            "  adding: content/yolov5/runs/train/ (stored 0%)\n",
            "  adding: content/yolov5/runs/train/exp/ (stored 0%)\n",
            "  adding: content/yolov5/runs/train/exp/labels.jpg (deflated 17%)\n",
            "  adding: content/yolov5/runs/train/exp/results.csv (deflated 73%)\n",
            "  adding: content/yolov5/runs/train/exp/opt.yaml (deflated 49%)\n",
            "  adding: content/yolov5/runs/train/exp/train_batch1.jpg (deflated 10%)\n",
            "  adding: content/yolov5/runs/train/exp/labels_correlogram.jpg (deflated 35%)\n",
            "  adding: content/yolov5/runs/train/exp/hyp.yaml (deflated 45%)\n",
            "  adding: content/yolov5/runs/train/exp/train_batch0.jpg (deflated 8%)\n",
            "  adding: content/yolov5/runs/train/exp/weights/ (stored 0%)\n",
            "  adding: content/yolov5/runs/train/exp/weights/best.pt (deflated 7%)\n",
            "  adding: content/yolov5/runs/train/exp/weights/last.pt (deflated 7%)\n",
            "  adding: content/yolov5/runs/train/exp/train_batch2.jpg (deflated 10%)\n",
            "  adding: content/yolov5/runs/train/exp/events.out.tfevents.1671864397.f3fc9c717b02.7931.0 (deflated 94%)\n",
            "  adding: content/yolov5/runs/train/exp2/ (stored 0%)\n",
            "  adding: content/yolov5/runs/train/exp2/labels.jpg (deflated 17%)\n",
            "  adding: content/yolov5/runs/train/exp2/val_batch1_labels.jpg (deflated 13%)\n",
            "  adding: content/yolov5/runs/train/exp2/val_batch0_pred.jpg (deflated 13%)\n",
            "  adding: content/yolov5/runs/train/exp2/results.csv (deflated 83%)\n",
            "  adding: content/yolov5/runs/train/exp2/val_batch2_labels.jpg (deflated 14%)\n",
            "  adding: content/yolov5/runs/train/exp2/opt.yaml (deflated 50%)\n",
            "  adding: content/yolov5/runs/train/exp2/PR_curve.png (deflated 13%)\n",
            "  adding: content/yolov5/runs/train/exp2/P_curve.png (deflated 11%)\n",
            "  adding: content/yolov5/runs/train/exp2/results.png (deflated 8%)\n",
            "  adding: content/yolov5/runs/train/exp2/train_batch1.jpg (deflated 10%)\n",
            "  adding: content/yolov5/runs/train/exp2/events.out.tfevents.1671864614.f3fc9c717b02.8891.0 (deflated 33%)\n",
            "  adding: content/yolov5/runs/train/exp2/labels_correlogram.jpg (deflated 35%)\n",
            "  adding: content/yolov5/runs/train/exp2/hyp.yaml (deflated 45%)\n",
            "  adding: content/yolov5/runs/train/exp2/val_batch2_pred.jpg (deflated 14%)\n",
            "  adding: content/yolov5/runs/train/exp2/train_batch0.jpg (deflated 8%)\n",
            "  adding: content/yolov5/runs/train/exp2/F1_curve.png (deflated 12%)\n",
            "  adding: content/yolov5/runs/train/exp2/val_batch0_labels.jpg (deflated 13%)\n",
            "  adding: content/yolov5/runs/train/exp2/val_batch1_pred.jpg (deflated 13%)\n",
            "  adding: content/yolov5/runs/train/exp2/weights/ (stored 0%)\n",
            "  adding: content/yolov5/runs/train/exp2/weights/best.pt (deflated 8%)\n",
            "  adding: content/yolov5/runs/train/exp2/weights/last.pt (deflated 8%)\n",
            "  adding: content/yolov5/runs/train/exp2/train_batch2.jpg (deflated 10%)\n",
            "  adding: content/yolov5/runs/train/exp2/confusion_matrix.png (deflated 20%)\n",
            "  adding: content/yolov5/runs/train/exp2/R_curve.png (deflated 11%)\n"
          ]
        }
      ],
      "source": [
        "!zip -r /content/runs.zip /content/yolov5/runs"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wwzaLywJc0gM"
      },
      "id": "wwzaLywJc0gM",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "TPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "72c31de2fcb247e5bf9362fe6f9621a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3f2e24910c90469a86cbd39b507b11ba",
              "IPY_MODEL_f87048e62e3047d681cf7bbc5f9fab22",
              "IPY_MODEL_d06e2f7335f14d038b48cad09755e215"
            ],
            "layout": "IPY_MODEL_f380d5a3546a424f8616389a58aeae03"
          }
        },
        "3f2e24910c90469a86cbd39b507b11ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5f54322be2049f28a2f5352f2069ebd",
            "placeholder": "​",
            "style": "IPY_MODEL_61fd4444b1e5493996729fe2728cdd0d",
            "value": "100%"
          }
        },
        "f87048e62e3047d681cf7bbc5f9fab22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_055ececfcc2a428abed8e217f203713e",
            "max": 14808437,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5692fa79a51842c298f4e27fbbc84eda",
            "value": 14808437
          }
        },
        "d06e2f7335f14d038b48cad09755e215": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d9e9b7a238449a5a8a82b5c2297099e",
            "placeholder": "​",
            "style": "IPY_MODEL_59287c4afa5b4463bc4e84373cadb1ad",
            "value": " 14.1M/14.1M [00:00&lt;00:00, 32.1MB/s]"
          }
        },
        "f380d5a3546a424f8616389a58aeae03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5f54322be2049f28a2f5352f2069ebd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61fd4444b1e5493996729fe2728cdd0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "055ececfcc2a428abed8e217f203713e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5692fa79a51842c298f4e27fbbc84eda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4d9e9b7a238449a5a8a82b5c2297099e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59287c4afa5b4463bc4e84373cadb1ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}